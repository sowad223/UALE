{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T10:12:48.245588Z",
     "iopub.status.busy": "2025-11-18T10:12:48.244919Z",
     "iopub.status.idle": "2025-11-18T13:58:40.359241Z",
     "shell.execute_reply": "2025-11-18T13:58:40.358297Z",
     "shell.execute_reply.started": "2025-11-18T10:12:48.245538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading dataset...\n",
      "Total images found: 34192\n",
      "\n",
      "==================== RUN 1/5 ====================\n",
      "Run 1 - Total params: 0.054M\n",
      "Run 1 → Acc: 57.63% | | F1: 56.54% | AUPRC: 62.71%\n",
      "\n",
      "==================== RUN 2/5 ====================\n",
      "Run 2 - Total params: 0.054M\n",
      "Run 2 → Acc: 66.79% | | F1: 65.64% | AUPRC: 73.43%\n",
      "\n",
      "==================== RUN 3/5 ====================\n",
      "Run 3 - Total params: 0.054M\n",
      "Run 3 → Acc: 54.36% | | F1: 52.79% | AUPRC: 62.25%\n",
      "\n",
      "==================== RUN 4/5 ====================\n",
      "Run 4 - Total params: 0.054M\n",
      "Run 4 → Acc: 62.39% | | F1: 61.51% | AUPRC: 68.02%\n",
      "\n",
      "==================== RUN 5/5 ====================\n",
      "Run 5 - Total params: 0.054M\n",
      "Run 5 → Acc: 59.22% | | F1: 58.16% | AUPRC: 65.15%\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS ACROSS 5 RUNS\n",
      "============================================================\n",
      "Accuracy : 60.08% ± 4.24%\n",
      "F1-Score : 58.93% ± 4.37%\n",
      "AUPRC    : 66.31% ± 4.11%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!pip install thop scikit-learn torch torchvision seaborn matplotlib numpy pillow -q\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    f1_score, precision_score, recall_score,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from PIL import Image\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from thop import profile\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "def load_benchmark_dataset_fixed():\n",
    "    base_path = \"/kaggle/input/benchmark/Benchmark Diagnostic MRI and Medical Imaging Dataset/Medical Imaging Dataset\"\n",
    "    \n",
    "    class_mapping = {\n",
    "        \"Low Medial Insertion of Common Bile Duct with Pancreas Divisum-20240916T165825Z-001\": \"Low Medial Insertion of Common Bile Duct with Pancreas Divisum\",\n",
    "        \"Inferior Vena Cava (IVC) Leiomyosarcoma-20240916T165709Z-001\": \"Inferior Vena Cava (IVC) Leiomyosarcoma\",\n",
    "        \"Acute Cerebellitis in HIV\": \"Acute Cerebellitis in HIV\",\n",
    "        \"Acute Unilateral Cerebellitis in HIV\": \"Acute Unilateral Cerebellitis in HIV\",\n",
    "        \"Adenomyosis in Gravid Uterus\": \"Adenomyosis in Gravid Uterus\",\n",
    "        \"Balloon Cell Cortical Dysplasia\": \"Balloon Cell Cortical Dysplasia\",\n",
    "        \"Bilateral Osgood-Schlatter Disease with Chronic Inflammatory Arthritis\": \"Bilateral Osgood-Schlatter Disease with Chronic Inflammatory Arthritis\",\n",
    "        \"Bilateral Ulnar Impaction Syndrome\": \"Bilateral Ulnar Impaction Syndrome\",\n",
    "        \"Carolis Disease\": \"Carolis Disease\",\n",
    "        \"Congenital Toxoplasmosis\": \"Congenital Toxoplasmosis\",\n",
    "        \"Congenital Vaginal Cyst\": \"Congenital Vaginal Cyst\",\n",
    "        \"Dermatomyositis\": \"Dermatomyositis\",\n",
    "        \"Fukuyama Muscular Dystrophy\": \"Fukuyama Muscular Dystrophy\",\n",
    "        \"Gamekeepers Thumb\": \"Gamekeepers Thumb\",\n",
    "        \"Hallervorden-Spatz Disease (now called Pantothenate Kinase-Associated Neurodegeneration)\": \"Hallervorden-Spatz Disease (now called Pantothenate Kinase-Associated Neurodegeneration)\",\n",
    "        \"Hepatocellular Carcinoma (HCC) and Dysplastic Nodules with Cirrhosis\": \"Hepatocellular Carcinoma (HCC) and Dysplastic Nodules with Cirrhosis\",\n",
    "        \"Japanese B Encephalitis or Epstein-Barr Encephalitis\": \"Japanese B Encephalitis or Epstein-Barr Encephalitis\",\n",
    "        \"Leighs Disease in Spinal Cord and Inferior Colliculi\": \"Leighs Disease in Spinal Cord and Inferior Colliculi\",\n",
    "        \"Lumbosacral Plexitis\": \"Lumbosacral Plexitis\",\n",
    "        \"Magnetic Resonance (MR) Brain\": \"Magnetic Resonance (MR) Brain\",\n",
    "        \"Magnetic Resonance (MR) Spine\": \"Magnetic Resonance (MR) Spine\",\n",
    "        \"Moyamoya Disease with Intraventricular Hemorrhage\": \"Moyamoya Disease with Intraventricular Hemorrhage\",\n",
    "        \"Myositis Ossificans Progressiva\": \"Myositis Ossificans Progressiva\",\n",
    "        \"Neurofibromatosis Type 1 (NF1) with Optic Glioma and Intracranial Extension\": \"Neurofibromatosis Type 1 (NF1) with Optic Glioma and Intracranial Extension\",\n",
    "        \"Optic Glioma\": \"Optic Glioma\",\n",
    "        \"Osmotic Demyelination Syndrome\": \"Osmotic Demyelination Syndrome\",\n",
    "        \"Pachygyria with Cerebellar Hypoplasia\": \"Pachygyria with Cerebellar Hypoplasia\",\n",
    "        \"Perisylvian Syndrome\": \"Perisylvian Syndrome\",\n",
    "        \"Pigmented Villonodular Synovitis (PVNS) of Ankle\": \"Pigmented Villonodular Synovitis (PVNS) of Ankle\",\n",
    "        \"Plexiform Neurofibroma with Sphenoid Wing Absence\": \"Plexiform Neurofibroma with Sphenoid Wing Absence\",\n",
    "        \"Rasmussens Encephalitis\": \"Rasmussens Encephalitis\",\n",
    "        \"Retinoblastoma with Intracranial Spread Along Cranial Nerve\": \"Retinoblastoma with Intracranial Spread Along Cranial Nerve\",\n",
    "        \"Right Brachial Plexitis\": \"Right Brachial Plexitis\",\n",
    "        \"Sjögrens Syndrome\": \"Sjögrens Syndrome\",\n",
    "        \"Sural Nerve Neurofibroma\": \"Sural Nerve Neurofibroma\",\n",
    "        \"Thoracic Outlet Syndrome\": \"Thoracic Outlet Syndrome\",\n",
    "        \"Tuberous Sclerosis\": \"Tuberous Sclerosis\",\n",
    "        \"Two-Week Follow-Up with Spectroscopy\": \"Two-Week Follow-Up with Spectroscopy\",\n",
    "        \"Typical Adrenoleukodystrophy\": \"Typical Adrenoleukodystrophy\",\n",
    "        \"Walker-Warburg Syndrome\": \"Walker-Warburg Syndrome\"\n",
    "    }\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name, subdir_name in class_mapping.items():\n",
    "        class_dir = os.path.join(base_path, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            subdir = os.path.join(class_dir, subdir_name)\n",
    "            if os.path.exists(subdir):\n",
    "                for file in os.listdir(subdir):\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.dcm', '.nii')):\n",
    "                        image_paths.append(os.path.join(subdir, file))\n",
    "                        labels.append(class_name)\n",
    "    \n",
    "    print(f\"Total images found: {len(image_paths)}\")\n",
    "    \n",
    "    unique_labels = sorted(list(set(labels)))\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    encoded_labels = [label_to_idx[label] for label in labels]\n",
    "    \n",
    "    return image_paths, encoded_labels, unique_labels, label_to_idx\n",
    "\n",
    "\n",
    "class BenchmarkMRIDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            img = torch.zeros(1, 224, 224)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "class MedicalMicroNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 8, 3, padding=1), nn.BatchNorm2d(8), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True), nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 64), nn.ReLU(inplace=True), nn.Dropout(0.2), nn.Linear(64, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class TextureNet(nn.Module):\n",
    "    def __init__(self, num_classes): super().__init__(); self.net = MedicalMicroNet(1, num_classes)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class ShapeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = MedicalMicroNet(2, num_classes)\n",
    "    def forward(self, x):\n",
    "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).view(1,1,3,3).to(x.device)\n",
    "        sobel_y = torch.tensor([[-1,-2,-1], [0,0,0], [1,2,1]], dtype=torch.float32).view(1,1,3,3).to(x.device)\n",
    "        edges_x = F.conv2d(x, sobel_x, padding=1)\n",
    "        edges_y = F.conv2d(x, sobel_y, padding=1)\n",
    "        edges = torch.sqrt(edges_x**2 + edges_y**2)\n",
    "        x_combined = torch.cat([x, edges], dim=1)\n",
    "        return self.net(x_combined)\n",
    "\n",
    "class IntensityNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = MedicalMicroNet(1, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = (x - x.mean(dim=(2,3), keepdim=True)) / (x.std(dim=(2,3), keepdim=True) + 1e-8)\n",
    "        return self.net(x)\n",
    "\n",
    "class SpatialNet(nn.Module):\n",
    "    def __init__(self, num_classes): super().__init__(); self.net = MedicalMicroNet(1, num_classes)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class MultiScaleNet(nn.Module):\n",
    "    def __init__(self, num_classes): super().__init__(); self.net = MedicalMicroNet(1, num_classes)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UltraLightUALE(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.texture_net = TextureNet(num_classes)\n",
    "        self.shape_net = ShapeNet(num_classes)\n",
    "        self.intensity_net = IntensityNet(num_classes)\n",
    "        self.spatial_net = SpatialNet(num_classes)\n",
    "        self.multiscale_net = MultiScaleNet(num_classes)\n",
    "        self.num_classes = num_classes\n",
    "    def forward(self, x):\n",
    "        p1 = self.texture_net(x)\n",
    "        p2 = self.shape_net(x)\n",
    "        p3 = self.intensity_net(x)\n",
    "        p4 = self.spatial_net(x)\n",
    "        p5 = self.multiscale_net(x)\n",
    "        preds = torch.stack([p1, p2, p3, p4, p5], dim=0)\n",
    "        ensemble_pred = torch.mean(preds, dim=0)\n",
    "        uncertainty = torch.var(preds, dim=0).mean(dim=1)\n",
    "        return ensemble_pred, uncertainty, preds\n",
    "\n",
    "\n",
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(256), transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(), transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(), transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(256), transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(), transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "    return train_transform, val_transform\n",
    "\n",
    "def train_one_run(model, train_loader, val_loader, epochs=100, patience=15):\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, verbose=False)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _, _ = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs, _, _ = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), f'best_model_temp.pth')\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(torch.load('best_model_temp.pth'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_with_auprc(model, test_loader, num_classes):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs, _, _ = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels_onehot = label_binarize(all_labels, classes=range(num_classes))\n",
    "    \n",
    "\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    auprc = dict()\n",
    "    for i in range(num_classes):\n",
    "        if np.sum(all_labels_onehot[:, i]) > 0:\n",
    "            precision[i], recall[i], _ = precision_recall_curve(all_labels_onehot[:, i], all_probs[:, i])\n",
    "            auprc[i] = auc(recall[i], precision[i])\n",
    "    \n",
    "    # Weighted average by support\n",
    "    weights = np.bincount(all_labels, minlength=num_classes)\n",
    "    weights = weights / weights.sum()\n",
    "    weighted_auprc = sum(auprc.get(i, 0) * weights[i] for i in range(num_classes))\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return acc, f1, weighted_auprc\n",
    "\n",
    "\n",
    "def run_multiple_experiments(n_runs=5):\n",
    "    print(\"Loading dataset...\")\n",
    "    image_paths, encoded_labels, unique_labels, _ = load_benchmark_dataset_fixed()\n",
    "    num_classes = len(unique_labels)\n",
    "    \n",
    "    results = {'accuracy': [], 'f1': [], 'auprc': []}\n",
    "    \n",
    "    for run in range(1, n_runs + 1):\n",
    "        print(f\"\\n{'='*20} RUN {run}/{n_runs} {'='*20}\")\n",
    "        set_seed(1000 + run) \n",
    "        \n",
    "  \n",
    "        train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "            image_paths, encoded_labels, test_size=0.2, random_state=42+run, stratify=encoded_labels)\n",
    "        \n",
    "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "            train_paths, train_labels, test_size=0.15, random_state=42+run, stratify=train_labels)\n",
    "        \n",
    "        train_transform, val_transform = get_transforms()\n",
    "        \n",
    "        train_dataset = BenchmarkMRIDataset(train_paths, train_labels, transform=train_transform)\n",
    "        val_dataset   = BenchmarkMRIDataset(val_paths,   val_labels,   transform=val_transform)\n",
    "        test_dataset  = BenchmarkMRIDataset(test_paths,  test_labels,  transform=val_transform)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "        val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "        \n",
    "        model = UltraLightUALE(num_classes=num_classes)\n",
    "        print(f\"Run {run} - Total params: {sum(p.numel() for p in model.parameters())/1e6:.3f}M\")\n",
    "        \n",
    "        model = train_one_run(model, train_loader, val_loader, epochs=100, patience=5)\n",
    "        \n",
    "        acc, f1, auprc = evaluate_with_auprc(model, test_loader, num_classes)\n",
    "        \n",
    "        results['accuracy'].append(acc * 100)\n",
    "        results['f1'].append(f1 * 100)\n",
    "        results['auprc'].append(auprc * 100)\n",
    "        \n",
    "        print(f\"Run {run} → Acc: {acc*100:.2f}% | | F1: {f1*100:.2f}% | AUPRC: {auprc*100:.2f}%\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL RESULTS ACROSS 5 RUNS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Accuracy : {np.mean(results['accuracy']):.2f}% ± {np.std(results['accuracy']):.2f}%\")\n",
    "    print(f\"F1-Score : {np.mean(results['f1']):.2f}% ± {np.std(results['f1']):.2f}%\")\n",
    "    print(f\"AUPRC    : {np.mean(results['auprc']):.2f}% ± {np.std(results['auprc']):.2f}%\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    final_results = run_multiple_experiments(n_runs=5)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7780436,
     "sourceId": 12341851,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
